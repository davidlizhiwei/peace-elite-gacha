#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é˜¿é‡Œäº‘ Fun-ASR è¯­éŸ³è¯†åˆ« Skill
æ ¹æ®å®˜æ–¹æ–‡æ¡£ï¼šhttps://www.alibabacloud.com/help/en/model-studio/real-time-speech-recognition

æ¨¡å‹ï¼šfun-asr-realtime (å®æ—¶è¯­éŸ³è¯†åˆ«)
æ¥å£ï¼šéæµå¼ call (é€‚åˆå½•éŸ³æ–‡ä»¶)
å»¶è¿Ÿï¼š~400ms é¦–åŒ…å»¶è¿Ÿ

ä½¿ç”¨æ–¹æ³•:
    from fun_asr import speech_to_text

    # ç®€å•è°ƒç”¨
    result = speech_to_text("audio.pcm")

    # æŒ‡å®šè¯­è¨€
    result = speech_to_text("audio.wav", language_hints=["zh", "en"])

    # å¼€å¯è¯­ä¹‰æ–­å¥
    result = speech_to_text("audio.mp3", semantic_punctuation_enabled=True)
"""

import os
import glob
from datetime import datetime
from typing import List, Optional, Dict, Any

import dashscope
from dashscope.audio.asr import Recognition, RecognitionCallback

# ==================== é…ç½® ====================
# API Key ä»ç¯å¢ƒå˜é‡è·å–
DASHSCOPE_API_KEY = os.environ.get("DASHSCOPE_API_KEY", "sk-c3276d00c66c4a759315b5cb0989db16")
dashscope.api_key = DASHSCOPE_API_KEY

# è¾“å‡ºç›®å½•
OUTPUT_DIR = os.path.join(os.path.dirname(__file__), "output")
os.makedirs(OUTPUT_DIR, exist_ok=True)

# ==================== æ”¯æŒçš„æ¨¡å‹ ====================
AVAILABLE_MODELS = {
    "fun-asr-realtime": "å®æ—¶è¯­éŸ³è¯†åˆ« (ç¨³å®šç‰ˆï¼Œæ¨è)",
    "fun-asr-realtime-2025-11-07": "å®æ—¶è¯­éŸ³è¯†åˆ« (å¿«ç…§ç‰ˆï¼Œè¿œåœº VAD ä¼˜åŒ–)",
    "fun-asr-realtime-2025-09-15": "å®æ—¶è¯­éŸ³è¯†åˆ« (å¤šè¯­è¨€)",
}

# ==================== æ”¯æŒçš„è¯­è¨€ ====================
SUPPORTED_LANGUAGES = {
    "zh": "ä¸­æ–‡",
    "en": "è‹±æ–‡",
    "ja": "æ—¥è¯­",
    "ko": "éŸ©è¯­",
    "vi": "è¶Šå—è¯­",
    "id": "å°å°¼è¯­",
    "th": "æ³°è¯­",
}

# ==================== å›è°ƒç±» ====================
class ASRResultCallback(RecognitionCallback):
    """ASR ç»“æœå›è°ƒç±»"""

    def __init__(self):
        self.sentences = []
        self.full_text = []

    def on_open(self) -> None:
        """è¿æ¥æ‰“å¼€å›è°ƒ"""
        print(f'[ASR] ğŸ”— è¿æ¥å·²æ‰“å¼€')

    def on_close(self) -> None:
        """è¿æ¥å…³é—­å›è°ƒ"""
        print(f'[ASR] ğŸ”Œ è¿æ¥å·²å…³é—­')

    def on_event(self, result) -> None:
        """äº‹ä»¶å›è°ƒ"""
        try:
            sentence = result.get_sentence()
            if sentence:
                if isinstance(sentence, dict):
                    text = sentence.get('text', '')
                    if text:
                        self.full_text.append(text)
                        self.sentences.append(sentence)
                        print(f'[ASR] ğŸ“ {text}')
        except Exception as e:
            print(f'[ASR] âŒ å›è°ƒé”™è¯¯ï¼š{e}')

    def on_complete(self) -> None:
        """å®Œæˆå›è°ƒ"""
        print(f'[ASR] âœ… è¯†åˆ«å®Œæˆ')

    def on_error(self, result) -> None:
        """é”™è¯¯å›è°ƒ"""
        print(f'[ASR] âŒ é”™è¯¯ï¼š{result}')


# ==================== ä¸»å‡½æ•° ====================
def speech_to_text(
    audio_file: str,
    model: str = "fun-asr-realtime",
    language_hints: Optional[List[str]] = None,
    sample_rate: int = 24000,
    audio_format: str = "pcm",
    semantic_punctuation_enabled: bool = False,
    verbose: bool = True
) -> Dict[str, Any]:
    """
    è¯­éŸ³è½¬æ–‡å­—

    å‚æ•°:
        audio_file: éŸ³é¢‘æ–‡ä»¶è·¯å¾„ (æ”¯æŒ pcm, wav, mp3, opus, speex, aac, amr)
        model: æ¨¡å‹åç§° (fun-asr-realtime, fun-asr-realtime-2025-11-07)
        language_hints: è¯­è¨€æç¤ºåˆ—è¡¨ (["zh", "en"])
        sample_rate: é‡‡æ ·ç‡ (Hz)ï¼Œé»˜è®¤ 24000
        audio_format: éŸ³é¢‘æ ¼å¼ (pcm, wav, mp3, opus, speex, aac, amr)
        semantic_punctuation_enabled: æ˜¯å¦å¼€å¯è¯­ä¹‰æ–­å¥
        verbose: æ˜¯å¦æ‰“å°æ—¥å¿—

    è¿”å›:
        dict: {
            "success": bool,
            "text": str (å®Œæ•´è¯†åˆ«æ–‡æœ¬),
            "sentences": list (å¥å­åˆ—è¡¨),
            "first_package_delay": float (é¦–åŒ…å»¶è¿Ÿ ms),
            "last_package_delay": float (å°¾åŒ…å»¶è¿Ÿ ms),
            "request_id": str,
            "error": str (é”™è¯¯ä¿¡æ¯ï¼Œå¦‚æœæœ‰)
        }
    """
    if not os.path.exists(audio_file):
        return {"success": False, "error": f"æ–‡ä»¶ä¸å­˜åœ¨ï¼š{audio_file}"}

    if verbose:
        print("=" * 60)
        print("é˜¿é‡Œäº‘ Fun-ASR è¯­éŸ³è¯†åˆ«")
        print("=" * 60)
        print(f"ğŸ§ éŸ³é¢‘ï¼š{audio_file}")
        print(f"ğŸ“Š å¤§å°ï¼š{os.path.getsize(audio_file) / 1024:.1f} KB")
        print(f"ğŸ” æ¨¡å‹ï¼š{model}")
        print(f"ğŸŒ è¯­è¨€ï¼š{language_hints or 'è‡ªåŠ¨æ£€æµ‹'}")

    try:
        # åˆ›å»ºå›è°ƒ
        callback = ASRResultCallback()

        # åˆ›å»ºè¯†åˆ«å®ä¾‹
        recognition = Recognition(
            model=model,
            callback=callback,
            format=audio_format,
            sample_rate=sample_rate,
            language_hints=language_hints or ["zh", "en"],
            semantic_punctuation_enabled=semantic_punctuation_enabled
        )

        if verbose:
            print(f"\nğŸ¤ å¼€å§‹è¯†åˆ«...")

        # éæµå¼è°ƒç”¨ï¼šç›´æ¥ä¼ å…¥æ–‡ä»¶è·¯å¾„
        result = recognition.call(audio_file)

        # è·å–è¯†åˆ«æ–‡æœ¬
        sentences = result.get_sentence()
        full_text = ""

        if sentences:
            if isinstance(sentences, list):
                full_text = ' '.join([
                    s.get('text', '')
                    for s in sentences
                    if isinstance(s, dict) and s.get('text')
                ])
            elif isinstance(sentences, dict):
                full_text = sentences.get('text', '')

        # è·å–æŒ‡æ ‡
        first_delay = recognition.get_first_package_delay()
        last_delay = recognition.get_last_package_delay()
        request_id = recognition.get_last_request_id()

        if verbose:
            if full_text:
                print(f"\nâœ… è¯†åˆ«æˆåŠŸï¼")
                print(f"ğŸ“ å†…å®¹ï¼š{full_text}")
                print(f"âš¡ é¦–åŒ…å»¶è¿Ÿï¼š{first_delay:.1f} ms")
                print(f"âš¡ å°¾åŒ…å»¶è¿Ÿï¼š{last_delay:.1f} ms")
                print(f"ğŸ“‹ Request ID: {request_id}")
            else:
                print(f"\nâš ï¸ æœªè·å–åˆ°è¯†åˆ«ç»“æœ")

        return {
            "success": True,
            "text": full_text,
            "sentences": sentences if sentences else [],
            "first_package_delay": first_delay,
            "last_package_delay": last_delay,
            "request_id": request_id
        }

    except Exception as e:
        error_msg = str(e)
        print(f"\nâŒ è¯†åˆ«å¤±è´¥ï¼š{error_msg}")
        return {
            "success": False,
            "error": error_msg,
            "text": "",
            "sentences": []
        }


# ==================== è¾…åŠ©å‡½æ•° ====================
def find_latest_tts_audio() -> Optional[str]:
    """æŸ¥æ‰¾æœ€æ–°çš„ TTS ç”Ÿæˆçš„éŸ³é¢‘æ–‡ä»¶"""
    script_dir = os.path.dirname(__file__)
    parent_dir = os.path.dirname(script_dir)
    project_dir = os.path.dirname(parent_dir)

    pcm_files = glob.glob(os.path.join(project_dir, "qwen3-tts-realtime-*.pcm"))
    pcm_files = [f for f in pcm_files if os.path.getsize(f) > 0]

    if pcm_files:
        return max(pcm_files, key=os.path.getmtime)
    return None


# ==================== å‘½ä»¤è¡Œè°ƒç”¨ ====================
if __name__ == "__main__":
    import sys

    # ä»å‘½ä»¤è¡Œè·å–æ–‡ä»¶è·¯å¾„
    if len(sys.argv) > 1:
        audio_file = sys.argv[1]
    else:
        # è‡ªåŠ¨æŸ¥æ‰¾æœ€æ–°çš„ TTS éŸ³é¢‘æ–‡ä»¶
        audio_file = find_latest_tts_audio()
        if not audio_file:
            print("âŒ æœªæ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶ï¼Œè¯·æä¾›æ–‡ä»¶è·¯å¾„")
            print("ç”¨æ³•ï¼špython fun-asr.py <éŸ³é¢‘æ–‡ä»¶>")
            sys.exit(1)
        print(f"è‡ªåŠ¨é€‰æ‹©æœ€æ–°éŸ³é¢‘ï¼š{audio_file}")

    # æ‰§è¡Œè¯†åˆ«
    result = speech_to_text(audio_file)

    if result["success"]:
        print(f"\nğŸ‰ å®Œæˆï¼è¯†åˆ«å†…å®¹ï¼š{result['text']}")
    else:
        print(f"\nâŒ å¤±è´¥ï¼š{result.get('error', 'æœªçŸ¥é”™è¯¯')}")
        sys.exit(1)
