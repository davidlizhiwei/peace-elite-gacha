#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é˜¿é‡Œäº‘ Qwen3-TTS è¯­éŸ³åˆæˆ Skill
æ ¹æ®å®˜æ–¹æ–‡æ¡£ï¼šhttps://github.com/aliyun/alibabacloud-bailian-speech-demo

æ¨¡å‹ï¼šqwen3-tts-flash-realtime (å®æ—¶è¯­éŸ³åˆæˆ)
æ¥å£ï¼šWebSocket
å»¶è¿Ÿï¼š~400ms é¦–éŸ³å»¶è¿Ÿ

ä½¿ç”¨æ–¹æ³•:
    from qwen3_tts import text_to_speech

    # ç®€å•è°ƒç”¨
    audio_file = text_to_speech("ä½ å¥½ï¼Œè¿™æ˜¯æµ‹è¯•æ–‡å­—")

    # æŒ‡å®šéŸ³è‰²
    audio_file = text_to_speech("ä½ å¥½", voice="Cherry")

    # æŒ‡ä»¤æ¨¡å¼ï¼ˆéœ€è¦ qwen3-tts-instruct-flash-realtimeï¼‰
    audio_file = text_to_speech("ä½ å¥½", use_instruct=True, instructions="è¯­é€Ÿè¾ƒå¿«")
"""

import os
import base64
import threading
import time
from datetime import datetime
from typing import Optional

import dashscope
from dashscope.audio.qwen_tts_realtime import QwenTtsRealtime, QwenTtsRealtimeCallback, AudioFormat

# ==================== é…ç½® ====================
# API Key ä»ç¯å¢ƒå˜é‡è·å–
DASHSCOPE_API_KEY = os.environ.get("DASHSCOPE_API_KEY", "sk-c3276d00c66c4a759315b5cb0989db16")
dashscope.api_key = DASHSCOPE_API_KEY

# è¾“å‡ºç›®å½•
OUTPUT_DIR = os.path.join(os.path.dirname(__file__), "output")
os.makedirs(OUTPUT_DIR, exist_ok=True)

# ==================== å¯ç”¨éŸ³è‰² ====================
AVAILABLE_VOICES = {
    "Cherry": "å¥³å£° - æ¸©æŸ”ç”œç¾",
    "Bella": "å¥³å£° - çŸ¥æ€§ä¼˜é›…",
    "Ethan": "ç”·å£° - æ²‰ç¨³ç£æ€§",
    "longshu_v2": "é¾™ä¹¦ - ç”·å£° (æ–°é—»æ’­æŠ¥)",
    "loongbella_v2": "Bella v2 - å¥³å£° (æ–°é—»æ’­æŠ¥)",
}

# ==================== å›è°ƒç±» ====================
class TTSResultCallback(QwenTtsRealtimeCallback):
    """TTS ç»“æœå›è°ƒç±»"""

    def __init__(self, output_file: str):
        self.complete_event = threading.Event()
        self.output_file = output_file
        self.file = open(output_file, 'wb')
        self.received_bytes = 0
        self.first_audio_time = None
        self.start_time = None

    def on_open(self) -> None:
        """è¿æ¥æ‰“å¼€å›è°ƒ"""
        self.start_time = time.time()
        print(f'[TTS] ğŸ”— è¿æ¥å·²æ‰“å¼€')

    def on_close(self, close_status_code: int, close_msg: str) -> None:
        """è¿æ¥å…³é—­å›è°ƒ"""
        self.file.close()
        duration = time.time() - self.start_time if self.start_time else 0
        print(f'[TTS] ğŸ”Œ è¿æ¥å·²å…³é—­ (è€—æ—¶ï¼š{duration:.2f}s)')

    def on_event(self, response: dict) -> None:
        """äº‹ä»¶å›è°ƒ"""
        try:
            event_type = response.get('type')

            if event_type == 'session.created':
                session_id = response.get('session', {}).get('id', 'unknown')
                print(f'[TTS] ğŸ“‹ ä¼šè¯åˆ›å»ºï¼š{session_id}')

            elif event_type == 'response.audio.delta':
                audio_b64 = response.get('delta')
                if audio_b64:
                    audio_data = base64.b64decode(audio_b64)
                    self.file.write(audio_data)
                    self.received_bytes += len(audio_data)

                    if self.first_audio_time is None:
                        self.first_audio_time = time.time()
                        delay = (self.first_audio_time - self.start_time) * 1000
                        print(f'[TTS] ğŸ“Š é¦–éŸ³å»¶è¿Ÿï¼š{delay:.1f}ms')

            elif event_type == 'response.done':
                print(f'[TTS] âœ… å“åº”å®Œæˆ')

            elif event_type == 'session.finished':
                print(f'[TTS] ğŸ ä¼šè¯ç»“æŸ')
                self.complete_event.set()

        except Exception as e:
            print(f'[TTS] âŒ å›è°ƒé”™è¯¯ï¼š{e}')

    def wait_for_finished(self):
        """ç­‰å¾…å®Œæˆ"""
        self.complete_event.wait()

    def get_first_audio_delay(self) -> float:
        """è·å–é¦–éŸ³å»¶è¿Ÿ (ms)"""
        if self.first_audio_time and self.start_time:
            return (self.first_audio_time - self.start_time) * 1000
        return 0


# ==================== ä¸»å‡½æ•° ====================
def text_to_speech(
    text: str,
    voice: str = "Cherry",
    use_instruct: bool = False,
    instructions: Optional[str] = None,
    output_file: Optional[str] = None,
    verbose: bool = True
) -> dict:
    """
    æ–‡å­—è½¬è¯­éŸ³

    å‚æ•°:
        text: è¦è½¬æ¢çš„æ–‡å­—
        voice: éŸ³è‰²åç§° (Cherry, Bella, Ethan, longshu_v2, loongbella_v2)
        use_instruct: æ˜¯å¦ä½¿ç”¨æŒ‡ä»¤æ¨¡å¼
        instructions: æŒ‡ä»¤æ–‡æœ¬ï¼ˆå¦‚"è¯­é€Ÿè¾ƒå¿«ï¼Œå¸¦æœ‰ä¸Šæ‰¬è¯­è°ƒ"ï¼‰
        output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆé»˜è®¤è‡ªåŠ¨ç”Ÿæˆï¼‰
        verbose: æ˜¯å¦æ‰“å°æ—¥å¿—

    è¿”å›:
        dict: {
            "success": bool,
            "file": str (éŸ³é¢‘æ–‡ä»¶è·¯å¾„),
            "size": int (æ–‡ä»¶å¤§å°å­—èŠ‚),
            "first_audio_delay": float (é¦–éŸ³å»¶è¿Ÿ ms),
            "session_id": str,
            "error": str (é”™è¯¯ä¿¡æ¯ï¼Œå¦‚æœæœ‰)
        }
    """
    if not text:
        return {"success": False, "error": "æ–‡å­—å†…å®¹ä¸ºç©º"}

    # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
    if output_file is None:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_file = os.path.join(OUTPUT_DIR, f"tts_{timestamp}.pcm")

    # é€‰æ‹©æ¨¡å‹
    model = "qwen3-tts-instruct-flash-realtime" if use_instruct else "qwen3-tts-flash-realtime"

    # WebSocket URL (åŒ—äº¬åœ°åŸŸ)
    ws_url = "wss://dashscope.aliyuncs.com/api-ws/v1/realtime"

    if verbose:
        print("=" * 60)
        print("é˜¿é‡Œäº‘ Qwen3-TTS è¯­éŸ³åˆæˆ")
        print("=" * 60)
        print(f"ğŸ“ æ–‡å­—ï¼š{text[:50]}...")
        print(f"ğŸ”Š æ¨¡å‹ï¼š{model}")
        print(f"ğŸ¤ éŸ³è‰²ï¼š{voice}")
        print(f"ğŸ’¾ è¾“å‡ºï¼š{output_file}")

    try:
        # åˆ›å»ºå›è°ƒ
        callback = TTSResultCallback(output_file)

        # åˆ›å»ºå®æ—¶ TTS å®ä¾‹
        qwen_tts_realtime = QwenTtsRealtime(
            model=model,
            callback=callback,
            url=ws_url
        )

        # è¿æ¥
        qwen_tts_realtime.connect()

        # é…ç½®ä¼šè¯
        session_args = {
            "voice": voice,
            "response_format": AudioFormat.PCM_24000HZ_MONO_16BIT,
            "mode": "server_commit"
        }

        if use_instruct and instructions:
            session_args["instructions"] = instructions
            session_args["optimize_instructions"] = True

        qwen_tts_realtime.update_session(**session_args)

        # å‘é€æ–‡æœ¬
        if verbose:
            print(f"ğŸ“¤ å‘é€æ–‡æœ¬...")

        qwen_tts_realtime.append_text(text)
        time.sleep(0.1)
        qwen_tts_realtime.finish()

        # ç­‰å¾…å®Œæˆ
        if verbose:
            print(f"â³ ç­‰å¾…å®Œæˆ...")

        callback.wait_for_finished()

        # è·å–ç»“æœ
        file_size = os.path.getsize(output_file)
        first_delay = callback.get_first_audio_delay()
        session_id = qwen_tts_realtime.get_session_id()

        if verbose:
            print(f"\nâœ… åˆæˆæˆåŠŸï¼")
            print(f"ğŸ’¾ æ–‡ä»¶ï¼š{output_file}")
            print(f"ğŸ“Š å¤§å°ï¼š{file_size / 1024:.1f} KB")
            print(f"âš¡ é¦–éŸ³å»¶è¿Ÿï¼š{first_delay:.1f} ms")
            print(f"ğŸ“‹ ä¼šè¯ ID: {session_id}")

        return {
            "success": True,
            "file": output_file,
            "size": file_size,
            "first_audio_delay": first_delay,
            "session_id": session_id
        }

    except Exception as e:
        error_msg = str(e)
        print(f"\nâŒ åˆæˆå¤±è´¥ï¼š{error_msg}")
        return {
            "success": False,
            "error": error_msg,
            "file": output_file if os.path.exists(output_file) else None
        }


# ==================== å‘½ä»¤è¡Œè°ƒç”¨ ====================
if __name__ == "__main__":
    import sys

    # é»˜è®¤æµ‹è¯•æ–‡å­—
    default_text = "ä½ å¥½ï¼è¿™æ˜¯é˜¿é‡Œäº‘é€šä¹‰åƒé—® Qwen3-TTS è¯­éŸ³åˆæˆæµ‹è¯•ã€‚"

    # ä»å‘½ä»¤è¡Œè·å–æ–‡å­—
    if len(sys.argv) > 1:
        text = " ".join(sys.argv[1:])
    else:
        text = default_text

    # æ‰§è¡Œè½¬æ¢
    result = text_to_speech(text, voice="Cherry")

    if result["success"]:
        print(f"\nğŸ‰ å®Œæˆï¼éŸ³é¢‘æ–‡ä»¶ï¼š{result['file']}")
    else:
        print(f"\nâŒ å¤±è´¥ï¼š{result.get('error', 'æœªçŸ¥é”™è¯¯')}")
        sys.exit(1)
